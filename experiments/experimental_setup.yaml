recourse_methods:
  ar:
    hyperparams:
      fs_size: 150
  causal_recourse:
    hyperparams:
  cchvae:
    hyperparams:
      n_search_samples: 100
      p_norm: 1
      step: 0.1
      max_iter: 1000
      binary_cat_features: True
      vae_params:
        layers: [512, 256, 8]
        train: True
        lambda_reg: 0.000001
        epochs: 5
        lr: 0.001
        batch_size: 32
  cem:
    hyperparams:
      batch_size: 1
      kappa: 0.1
      init_learning_rate: 0.01
      binary_search_steps: 9
      max_iterations: 100
      initial_const: 10
      beta: 0.9
      gamma: 0.0
      mode: "PN"
      num_classes: 2
      ae_params:
        hidden_layer: [20, 10, 7]
        train_ae: True
        epochs: 5
  cem_vae:
    hyperparams:
      batch_size: 1
      kappa: 0.1
      init_learning_rate: 0.01
      binary_search_steps: 9
      max_iterations: 100
      initial_const: 10
      beta: 0.9
      gamma: 1.0
      mode: "PN"
      num_classes: 2
      ae_params:
        hidden_layer: [20, 10, 7]
        train_ae: True
        epochs: 5
  claproar:
    hyperparams:
      individual_cost_lambda: 0.1
      external_cost_lambda: 0.1
      learning_rate: 0.01
      max_iter: 100
      tol: 0.0001
      target_class: 1
  clue:
    hyperparams:
      train_vae: True
      width: 10
      depth: 3
      latent_dim: 12
      batch_size: 64
      epochs: 1
      lr: 0.001
      early_stop: 10
  cruds:
    hyperparams:
      lambda_param: 0.001
      optimizer: "RMSprop"
      lr: 0.008
      max_iter: 2000
      vae_params:
        layers: [16, 8]
        train: True
        epochs: 5
        lr: 0.001
        batch_size: 32
  dice:
    hyperparams:
      num: 1
      desired_class: 1
      posthoc_sparsity_param: 0
  face_knn:
    hyperparams:
      mode: "knn"
      fraction: 0.15
  face_epsilon:
    hyperparams:
      mode: "epsilon"
      fraction: 0.15
  feature_tweak:
    hyperparams:
  focus:
    hyperparams:
  gravitational:
    hyperparams:
      prediction_loss_lambda: 1
      original_dist_lambda: 0.5
      grav_penalty_lambda: 1.05
      learning_rate: 0.01
      num_steps: 100
      target_class: 1
      scheduler_step_size: 100
      scheduler_gamma: 0.5
  greedy:
    hyperparams:
      lambda_param: 0.05
      step_size: 0.05
      max_iter: 100
      locked_features: []
      target_class: 1
  gs:
    hyperparams:
  mace:
    hyperparams:
  revise:
    hyperparams:
      lambda: 0.5
      optimizer: "adam"
      lr: 0.1
      max_iter: 1500
      target_class: [0, 1]
      binary_cat_features: True
      vae_params:
        layers: [512, 256, 8]
        activFun:
        train: True
        lambda_reg: 0.000001
        epochs: 5
        lr: 0.001
        batch_size: 32
  wachter:
    hyperparams:
      loss_type: "BCE"
      binary_cat_features: True
  cfvae:
    hyperparams:
       encoded_size: 10
       train: True
  cfrl:
    hyperparams:
       seed: 0
       autoencoder_batch_size: 128
       autoencoder_target_steps: 100_000
       autoencoder_lr: 1e-3
       autoencoder_latent_dim: 15
       autoencoder_hidden_dim: 128
       coeff_sparsity: 0.5
       coeff_consistency: 0.5
       train_steps: 100_000
       batch_size: 128
       train: True
  probe:
    hyperparams:
  roar:
    hyperparams:
  larr:
    hyperparams:
      alpha: 0.5
      beta: 1.0
  rbr:
    hyperparams:
      train_data: None
      device: "cpu"
